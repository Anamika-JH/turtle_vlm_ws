# Turtle VLM Workspace â€“ ROS + YOLO + LLM

A complete **ROS Noetic** workspace that turns a (simulated or real) TurtleBot3 Burger with an Intel RealSense depth camera into a conversational robot:

* **Perception:** YOLO v8 + MiDaS depth for 3-D object poses, published via a simple service (`/get_seen_objects`).
* **Reasoning / Language:** lightweight LLM front-end that converts natural-language commands into a structured **action dictionary**.
* **Control & Navigation:** turns these actions into `move_base` goals or direct `cmd_vel` twists.
* **Chat GUI:** Tkinter interface with speech I/O and image previews.
* **Gazebo world:** ready-to-run CPS lab environment with RViz configs.

<p align="center">
  <img src="https://raw.githubusercontent.com/Anamika-JH/turtle_vlm_ws/main/docs/preview.gif" width="650">
</p>

---

### ğŸ“ Directory layout
```text
turtle_vlm_ws/
â”œâ”€â”€ .catkin_workspace
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ turtle_vlm_chat/             # ğŸ”‘ Main package (code + configs)
â”‚   â”œâ”€â”€ turtle_vlm_gazebo/           # Gazebo world, RViz config, launch files
â”‚   â”œâ”€â”€ turtle_vlm_perception/       # Placeholder for future C++/CUDA nodes
â”‚   â””â”€â”€ turtlebot3_description_custom/  # Custom URDF for TurtleBot3 + Realsense
â”œâ”€â”€ frames.gv
